{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85685bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50,vgg16, mobilenet_v3_large ,resnet101\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from data.ImbalanceCIFAR import IMBALANCECIFAR10, IMBALANCECIFAR100\n",
    "from data import dataloader\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "def load_cifar10(batch_size, num_workers, val_indices):\n",
    "    # Adjust these transforms to the needs of your neural network\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),  # Resize images to 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Split the trainset into train and validation sets using given indices\n",
    "    valset = torch.utils.data.Subset(full_trainset, val_indices)\n",
    "    train_indices = [idx for idx in range(len(full_trainset)) if idx not in val_indices]\n",
    "    trainset = torch.utils.data.Subset(full_trainset, train_indices)\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return trainloader, valloader, testloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_indices(val_size, total_size, seed):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(total_size)\n",
    "    val_indices = indices[:val_size]\n",
    "    return val_indices\n",
    "\n",
    "\n",
    "def compute_uce(probs, targets, n_bins=10):\n",
    "    _, nattrs =probs.size()\n",
    "    nattrs = torch.tensor(nattrs) \n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    uce = 0\n",
    "    bin_uncertainties = []\n",
    "    bin_errors = []\n",
    "    prop_in_bin_values = []\n",
    "    bin_n_samples = []\n",
    "    bin_variances = []\n",
    "    # Compute the uncertainty values (entropy)\n",
    "    uncertainties = (1/torch.log(nattrs))*(-torch.sum(probs * torch.log(probs + 1e-12), dim=1))\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (uncertainties >= bin_lower) * (uncertainties < bin_upper)\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        prop_in_bin_values.append(prop_in_bin.item() if prop_in_bin.item() > 0 else None)\n",
    "        if prop_in_bin.item() > 0:\n",
    "            sample_indices = torch.where(in_bin)[0]\n",
    "            bin_targets = targets[sample_indices]\n",
    "            bin_probs = probs[sample_indices]\n",
    "            error_in_bin = (bin_targets != torch.argmax(bin_probs, dim=1)).float().mean()\n",
    "            avg_uncertainty_in_bin = uncertainties[in_bin].mean()\n",
    "            uce += torch.abs(avg_uncertainty_in_bin - error_in_bin) * prop_in_bin\n",
    "            bin_uncertainties.append(avg_uncertainty_in_bin.item())\n",
    "            bin_errors.append(error_in_bin.item())\n",
    "            n_samples_in_bin = sample_indices.size(0)\n",
    "            bin_n_samples.append(n_samples_in_bin)\n",
    "            bin_variances.append(torch.var((bin_targets != torch.argmax(bin_probs, dim=1)).float()).item())\n",
    "        else:\n",
    "            bin_uncertainties.append(None)\n",
    "            bin_errors.append(None)\n",
    "            bin_n_samples.append(None)\n",
    "            bin_variances.append(None)\n",
    "\n",
    "    return uce, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances\n",
    "def create_model(mc_dropout=False, dropout_rate=0.1):\n",
    "    model = resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    if mc_dropout:\n",
    "        model.fc = nn.Sequential(nn.Dropout(dropout_rate), nn.Linear(num_ftrs, 10))\n",
    "    else:\n",
    "        model.fc = nn.Linear(num_ftrs, 10)\n",
    "    return model\n",
    "\n",
    "def validate(model, valloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels,_ in valloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            # Append labels and predictions for each batch\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    accuracy = accuracy_score(torch.cat(all_labels).numpy(), torch.cat(all_preds).numpy())\n",
    "    average_loss = running_loss / len(valloader.dataset)\n",
    "    return average_loss, accuracy\n",
    "\n",
    "def train(model, trainloader, valloader, criterion, optimizer, device, num_epochs, model_save_path):\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels,_) in tqdm(enumerate(trainloader)):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        training_loss = running_loss / len(trainloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {training_loss}\")\n",
    "\n",
    "        # Validate after each epoch and save model if validation accuracy improves\n",
    "        val_loss, val_accuracy = validate(model, valloader, criterion, device)\n",
    "        print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print(f\"Improved validation accuracy: {best_accuracy}, saving model...\\n\")\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "def test(model, testloader, criterion, device, mc_dropout=False, T=100):\n",
    "    model.eval()\n",
    "    if mc_dropout:\n",
    "        enable_dropout(model)  # Only activate Dropout layers\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels,_ in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if mc_dropout:\n",
    "                # Apply dropout by predicting T times and averaging\n",
    "                outputs = torch.stack([model(images) for _ in range(T)], dim=0)\n",
    "                output_mean = outputs.mean(dim=0)\n",
    "                loss = criterion(output_mean, labels)\n",
    "                preds = output_mean.argmax(dim=1)\n",
    "                all_probs.append(F.softmax(output_mean, dim=1).cpu())  # Store output_mean for MC Dropout mode\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                all_probs.append(F.softmax(outputs, dim=1).cpu())\n",
    "                \n",
    "            # Append labels and predictions for each batch\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    \n",
    "    calibration_error = running_loss / len(testloader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    uce, _, _, _, _, _ = compute_uce(torch.from_numpy(all_probs), torch.from_numpy(all_labels))\n",
    "\n",
    "    return calibration_error, accuracy, uce\n",
    "\n",
    "def enable_dropout(model):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.train()\n",
    "def load_model(model, load_path):\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    return model\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.5, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "def plot_and_save_confusion_matrix(logits, labels, save_path=None):\n",
    "    # Calculate predicted labels\n",
    "    _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # Transform labels to numpy for x and y axis\n",
    "    classes = labels.unique().cpu().numpy()\n",
    "\n",
    "    # Set the x and y axis labels\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # Save the figure if a path is provided\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved confusion matrix to {save_path}\")\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f91ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6bd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(seed, batch_size_,imb_ratio):\n",
    "\n",
    "    \n",
    "    train_loader = dataloader.load_data(data_root='./cifar-10-batches-py', dataset='CIFAR10_LT'\n",
    "                                        , phase='train', batch_size=batch_size_, shuffle=True,cifar_imb_ratio = imb_ratio)\n",
    "    val_loader = dataloader.load_data(data_root='./cifar-10-batches-py', dataset='CIFAR10_LT'\n",
    "                                      , phase='val', batch_size=batch_size_, shuffle=False,cifar_imb_ratio = imb_ratio)\n",
    "    test_loader = dataloader.load_data(data_root='./cifar-10-batches-py', dataset='CIFAR10_LT'\n",
    "                                       , phase='test', batch_size=batch_size_, shuffle=False,cifar_imb_ratio = imb_ratio)\n",
    "\n",
    "    \n",
    "#     train_dataset=IMBALANCECIFAR10('train', imbalance_ratio=20, root='dataset/')\n",
    "#     val_dataset=IMBALANCECIFAR10('val', imbalance_ratio=20, root='dataset/')\n",
    "#     test_dataset=IMBALANCECIFAR10('test', imbalance_ratio=20, root='dataset/')\n",
    "#     # 創建數據加載器\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=4)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=test_batch_size, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce0f12",
   "metadata": {},
   "source": [
    "### 測試不同的DATASET SPLILT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843f80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed_list,ep,save_model,parm,imb_ratio):\n",
    "    learning_rate = 0.0005\n",
    "    batch_size = 512\n",
    "    \n",
    "\n",
    "    num_epochs = ep\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Define the size of validation set and total size of dataset\n",
    "    val_size = 5000\n",
    "    total_size = 50000\n",
    "\n",
    "    for seed in seed_list:\n",
    "        print(f\"Training model with different split = {seed}\")\n",
    "\n",
    "        trainloader, valloader, testloader = create_dataloaders(seed, batch_size,imb_ratio)        \n",
    "\n",
    "        criterion = FocalLoss(alpha=parm[0], gamma=parm[1])\n",
    "\n",
    "#         dropout_rates = [0.5, 0.4, 0.3 ,0.2, 0.1]\n",
    "        dropout_rates = [0.5]\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for mc_dropout in [False]:  # use MC dropout\n",
    "            for dropout_rate in dropout_rates:\n",
    "                print(f\"Training model with MC Dropout = {mc_dropout}, Dropout Rate = {dropout_rate}\")\n",
    "                model = create_model(mc_dropout, dropout_rate)\n",
    "                model = model.to(device)\n",
    "                \n",
    "#                 optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
    "#                             momentum=0.9,\n",
    "#                             weight_decay=2e-4)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                # Create a file name to save the best model for each dropout rate\n",
    "                best_model_save_path = f\"2_best_model_seed_{seed}_dropout_{dropout_rate}_false_ep{num_epochs}_{save_model}.pt\"\n",
    "\n",
    "                # Train the model, validating and saving the best model after each epoch\n",
    "                model = train(model, trainloader, valloader, criterion, optimizer, device, num_epochs, best_model_save_path)\n",
    "\n",
    "                calibration_error, accuracy, uce = test(model, testloader, criterion, device, mc_dropout)\n",
    "                print(f\"Test Calibration Error: {calibration_error}, Test Accuracy: {accuracy}, UCE: {uce}\\n\")\n",
    "\n",
    "                results.append({\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'calibration_error': calibration_error,\n",
    "                    'accuracy': accuracy,\n",
    "                    'uce': uce\n",
    "                })\n",
    "\n",
    "        #         # Save the final model state as well, if needed\n",
    "        #         final_model_save_path = f\"final_model_seed_{seed}_dropout_{dropout_rate}_true_.pt\"\n",
    "        #         torch.save(model.state_dict(), final_model_save_path)\n",
    "\n",
    "            # Save results to csv file\n",
    "#             df = pd.DataFrame(results)\n",
    "#             df.to_csv(str(seed)+'_'+'dropout_experiments_results.csv', index=False)\n",
    "\n",
    "            # Print out results\n",
    "            for result in results:\n",
    "                print(f\"Dropout Rate: {result['dropout_rate']}, Test Calibration Error: {result['calibration_error']}, Test Accuracy: {result['accuracy']}, UCE: {result['uce']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb345d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     main([3],10,1,parm = [1.,0.],imb_ratio= 50)\n",
    "#     main([4],35,1,parm = [0.6,3.],imb_ratio= 50)\n",
    "#     main([5],20,3,parm = [0.5,8.],imb_ratio= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44640682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b503e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd099bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error_rates(uncertainties, bin_uncertainties, bin_errors):\n",
    "    error_rates = []\n",
    "    for uncertainty in uncertainties:\n",
    "        found = False\n",
    "        for idx, (bin_uncertainty_lower, bin_uncertainty_upper, bin_error) in enumerate(zip(bin_uncertainties[:-1], bin_uncertainties[1:], bin_errors)):\n",
    "            if bin_uncertainty_lower is not None and bin_uncertainty_upper is not None and bin_error is not None:\n",
    "                if bin_uncertainty_lower <= uncertainty.item() < bin_uncertainty_upper:\n",
    "\n",
    "                    error_rates.append(bin_error)\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found:\n",
    "            found_= False\n",
    "            if bin_uncertainties[0] is not None: \n",
    "                if 0 <=uncertainty< bin_uncertainties[0]:\n",
    "                    error_rates.append(bin_errors[0])\n",
    "                    found_= True\n",
    "                else:    \n",
    "                    for bin_error in reversed(bin_errors):\n",
    "                        if bin_error is not None:\n",
    "                            error_rates.append(bin_error)\n",
    "                            found_= True\n",
    "                            break\n",
    "            else:\n",
    "                if bin_uncertainties[1] is not None: \n",
    "                    error_rates.append(bin_errors[1])\n",
    "                    found_= True\n",
    "                else:\n",
    "                    error_rates.append(bin_errors[2])\n",
    "                    found_= True\n",
    "                    \n",
    "            if not found_:\n",
    "                if bin_uncertainties[4] is not None and 0 <=uncertainty< bin_uncertainties[4]: \n",
    "                    error_rates.append(bin_errors[4])\n",
    "                    found_= True\n",
    "            if not found_:\n",
    "                if bin_uncertainties[8] is not None and bin_uncertainties[8] <=uncertainty< 1: \n",
    "                    error_rates.append(bin_errors[8])\n",
    "                    found_= True\n",
    "                \n",
    "\n",
    "    return torch.tensor(error_rates)\n",
    "\n",
    "def cal_accuracy(y_true, y_pred):\n",
    "\n",
    "    # 計算正確預測的數量\n",
    "    correct_predictions = torch.sum(y_true == y_pred)\n",
    "\n",
    "    # 計算準確度\n",
    "    accuracy = correct_predictions.item() / y_true.size(0)\n",
    "\n",
    "    return accuracy\n",
    "def choose_best_expert_ex(probs_expert1, probs_expert2, targets,val_uce_list_ep1,val_uce_list_ep2,weight_ep1,weight_ep2, n_bins=10):\n",
    "    # Compute UCE and bin values for both experts\n",
    "\n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets, n_bins)\n",
    "\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "#     print(probs_expert1)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    # Find error rates for both experts\n",
    "#     print(uncertainties_expert1,bin_uncertainties_expert1,bin_errors_expert1)\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "    \n",
    "    error_rates_expert1 = (error_rates_expert1/weight_ep1)\n",
    "    error_rates_expert2 = (error_rates_expert2/weight_ep2)\n",
    "    \n",
    "    chosen_expert = (error_rates_expert1 < error_rates_expert2).cuda()\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "\n",
    "    # Choose the final prediction based on the chosen expert\n",
    "    final_predictions = torch.where(chosen_expert, preds_expert1, preds_expert2)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "def choose_best_three_expert(probs_expert1,probs_expert2,probs_expert3, targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3,weight_ep1,weight_ep2,weight_ep3, n_bins=10):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets_pairs, n_bins)\n",
    "#     uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_expert3, targets, n_bins)\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    _, nattrs = probs_expert2.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "    error_rates_expert1 = (error_rates_expert1/weight_ep1)\n",
    "    error_rates_expert2 = (error_rates_expert2/weight_ep2)\n",
    "    error_rates_expert3 = (error_rates_expert3/weight_ep3)\n",
    "    \n",
    "    \n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "    min_error_rate_indices = min_error_rate_indices.to(device)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1, \n",
    "                                    torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "    std_deviation_per_position = torch.std(error_rates, dim=0)\n",
    "    mean_value = torch.mean(std_deviation_per_position)\n",
    "    print(\"mean: \",mean_value)\n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "\n",
    "def voting(preds_expert1: List[int], preds_expert2: List[int], preds_expert3: List[int], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2, 3], \"Default expert must be either 1, 2, or 3\"\n",
    "    \n",
    "    final_preds = []\n",
    "    for p1, p2, p3 in zip(preds_expert1, preds_expert2, preds_expert3):\n",
    "        vote_counts = Counter([p1, p2, p3])\n",
    "        max_vote_count = max(vote_counts.values())\n",
    "        most_common = [k for k, v in vote_counts.items() if v == max_vote_count]\n",
    "        \n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_preds.append(p1)\n",
    "            elif default_expert == 2:\n",
    "                final_preds.append(p2)\n",
    "            else:  # default_expert == 3\n",
    "                final_preds.append(p3)\n",
    "        else:\n",
    "            final_preds.append(most_common[0])\n",
    "    \n",
    "\n",
    "    final_preds = torch.tensor(final_preds, dtype=torch.int64)\n",
    "    return final_preds\n",
    "def weighted_voting(preds_expert1: List[int], preds_expert2: List[int], preds_expert3: List[int], weights: List[float], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2, 3], \"Default expert must be either 1, 2, or 3\"\n",
    "    \n",
    "    final_preds = []\n",
    "    for p1, p2, p3 in zip(preds_expert1, preds_expert2, preds_expert3):\n",
    "        weighted_vote_counts = Counter()\n",
    "        for pred, weight in zip([p1, p2, p3], weights):\n",
    "            weighted_vote_counts[pred] += weight\n",
    "        \n",
    "        max_vote_count = max(weighted_vote_counts.values())\n",
    "        most_common = [k for k, v in weighted_vote_counts.items() if v == max_vote_count]\n",
    "        \n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_preds.append(p1)\n",
    "            elif default_expert == 2:\n",
    "                final_preds.append(p2)\n",
    "            else:  # default_expert == 3\n",
    "                final_preds.append(p3)\n",
    "        else:\n",
    "            final_preds.append(most_common[0])\n",
    "    \n",
    "    final_preds = torch.tensor(final_preds, dtype=torch.int64)\n",
    "\n",
    "    # 将列表转换为一个 PyTorch 张量\n",
    "    final_preds = torch.tensor(final_preds)\n",
    "\n",
    "    return final_preds\n",
    "\n",
    "\n",
    "def voting2(preds_expert1: List[int], preds_expert2: List[int], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2], \"Default expert must be either 1 or 2\"\n",
    "    \n",
    "    final_preds = []\n",
    "    for p1, p2 in zip(preds_expert1, preds_expert2):\n",
    "        vote_counts = Counter([p1, p2])\n",
    "        max_vote_count = max(vote_counts.values())\n",
    "        most_common = [k for k, v in vote_counts.items() if v == max_vote_count]\n",
    "        \n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_preds.append(p1)\n",
    "            else:  # default_expert == 2\n",
    "                final_preds.append(p2)\n",
    "        else:\n",
    "            final_preds.append(most_common[0])\n",
    "    \n",
    "    final_preds = torch.tensor(final_preds, dtype=torch.int64)\n",
    "    return final_preds\n",
    "\n",
    "def weighted_voting2(preds_expert1: List[int], preds_expert2: List[int], weights: List[float], default_expert: int) -> torch.Tensor:\n",
    "    assert default_expert in [1, 2], \"Default expert must be either 1 or 2\"\n",
    "    \n",
    "    final_preds = []\n",
    "    for p1, p2 in zip(preds_expert1, preds_expert2):\n",
    "        weighted_vote_counts = Counter()\n",
    "        for pred, weight in zip([p1, p2], weights):\n",
    "            weighted_vote_counts[pred] += weight\n",
    "        \n",
    "        max_vote_count = max(weighted_vote_counts.values())\n",
    "        most_common = [k for k, v in weighted_vote_counts.items() if v == max_vote_count]\n",
    "        \n",
    "        if len(most_common) > 1:\n",
    "            if default_expert == 1:\n",
    "                final_preds.append(p1)\n",
    "            else:  # default_expert == 2\n",
    "                final_preds.append(p2)\n",
    "        else:\n",
    "            final_preds.append(most_common[0])\n",
    "    \n",
    "    final_preds = torch.tensor(final_preds, dtype=torch.int64)\n",
    "    return final_preds\n",
    "def product_of_experts(predictions):\n",
    "    # Multiply predictions together\n",
    "    product = torch.prod(predictions, dim=0)\n",
    "    \n",
    "    # Normalize result\n",
    "    product /= torch.sum(product)\n",
    "    \n",
    "    return product\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_dot_UCE_diagram(uce_value, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances, model_index, threshold=0.005):\n",
    "    global save_name\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect calibration\")\n",
    "    \n",
    "    # 筛选prop_in_bin值大于等于threshold的点\n",
    "    valid_indices = [i for i, prop in enumerate(prop_in_bin_values) if prop is not None and prop >= threshold]\n",
    "    valid_bin_uncertainties = [bin_uncertainties[i] for i in valid_indices]\n",
    "    valid_bin_errors = [bin_errors[i] for i in valid_indices]\n",
    "    valid_prop_in_bin_values = [prop_in_bin_values[i] for i in valid_indices]\n",
    "    valid_bin_n_samples  = [bin_n_samples[i] for i in valid_indices]\n",
    "    valid_bin_variances  = [bin_variances[i] for i in valid_indices]\n",
    "    \n",
    "    # 计算中心点\n",
    "    centers = [0.05 + 0.1 * i for i in range(10)]\n",
    "    bins = [0 + 0.1 * i for i in range(11)]  # Including the rightmost edge for binning\n",
    "    \n",
    "    # 对bin_uncertainties值进行分箱，并找到对应的中心点\n",
    "    hist_values = np.digitize(valid_bin_uncertainties, bins) - 1\n",
    "    hist_centers = [centers[i] for i in hist_values]\n",
    "    \n",
    "    # Use Normalize and colormap to change the color of the bars based on bin_n_samples\n",
    "    norm = Normalize(vmin=min(valid_bin_n_samples), vmax=max(valid_bin_n_samples))\n",
    "    colormap = cm.cividis   # Changed to plasma colormap\n",
    "    colors = [colormap(norm(value)) for value in valid_bin_n_samples]\n",
    "    \n",
    "    plt.bar(hist_centers, valid_bin_errors, width=0.05, color=colors)\n",
    "    plt.xlabel(\"Uncertainty\", fontsize=14)\n",
    "    plt.ylabel(\"Error\", fontsize=14)\n",
    "    plt.title(\"Reliability Diagram for Model {} (UCE={:.4f})\".format(model_index , uce_value.item()), fontsize=16)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1), fontsize=12)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1), fontsize=12)\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    sm = cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "    sm.set_array([])  # You can set a dummy array\n",
    "    cbar = plt.colorbar(sm, orientation='vertical', label='Number of Samples')\n",
    "    cbar.set_label('Number of Samples', rotation=270, labelpad=15)\n",
    "\n",
    "    for i, txt in enumerate(valid_bin_n_samples):\n",
    "        plt.annotate(\"n={}\".format(txt), (hist_centers[i], valid_bin_errors[i]), fontsize=8, ha='center', va='bottom', textcoords=\"offset points\", xytext=(0,5))\n",
    "#         plt.annotate(\"var={:.2f}\".format(valid_bin_variances[i]), (hist_centers[i], valid_bin_errors[i]), fontsize=8, ha='center', va='bottom', textcoords=\"offset points\", xytext=(0,20))\n",
    "\n",
    "    Path('plt/').mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig('plt/'+save_name +\"UCE_model_{}.svg\".format(model_index))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2c9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_three_expert(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets_pairs, n_bins)\n",
    "#     uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_expert3, targets, n_bins)\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "    min_error_rate_indices = min_error_rate_indices.to(device)\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                    torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "    \n",
    "    \n",
    "    POE_probs_ = torch.stack([probs_expert1, probs_expert2,probs_expert3])\n",
    "    POE_probs = product_of_experts(POE_probs_).to(device)\n",
    "    POE_pred = torch.argmax(POE_probs, axis=1)\n",
    "    \n",
    "    POE_pred = torch.tensor(POE_pred)  # Convert numpy array to torch tensor\n",
    "\n",
    "    SOE_probs_ = (probs_expert1+probs_expert2+probs_expert3)/3\n",
    "    SOE_probs_=SOE_probs_.to(device)\n",
    "    SOE_pred = torch.argmax(SOE_probs_, axis=1).to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    initial_predictions_probs = torch.where(min_error_rate_indices.unsqueeze(-1) == 0, probs_expert1,\n",
    "                                           torch.where(min_error_rate_indices.unsqueeze(-1) == 1, probs_expert2, probs_expert3))\n",
    "    \n",
    "    uce_expert_SPE, _, _, _,_,_ =compute_uce(initial_predictions_probs, targets)\n",
    "    uce_expert_SOE, _, _, _,_,_ =compute_uce(SOE_probs_, targets)\n",
    "    uce_expert_POE, _, _, _,_,_ =compute_uce(POE_probs, targets)\n",
    "    print(\"SPE_UCE: \",uce_expert_SPE,\"SOE_UCE: \",uce_expert_SOE,\"POE_UCE: \",uce_expert_POE)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b9a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_learning(models, data_loaders, criterion, device, phase,mc_dropout=False, T=1):\n",
    "    \n",
    "    global val_uce_list_ep1\n",
    "    global val_uce_list_ep2\n",
    "    global val_uce_list_ep3\n",
    "    global save_name\n",
    "    \n",
    "    model_1, model_2, model_3 = models['model_3'], models['model_4'], models['model_5']\n",
    "\n",
    "    model_1.eval()\n",
    "    model_2.eval()\n",
    "    model_3.eval()\n",
    "    \n",
    "    if mc_dropout:\n",
    "        enable_dropout(model_1)  \n",
    "        enable_dropout(model_2)  \n",
    "        enable_dropout(model_3)  \n",
    "\n",
    "    data_loader_1, data_loader_2, data_loader_3 = data_loaders['data_loader_3'][phase], data_loaders['data_loader_4'][phase], data_loaders['data_loader_5'][phase]\n",
    "\n",
    "    running_loss_1 = 0.0\n",
    "    running_loss_2 = 0.0\n",
    "    running_loss_3 = 0.0\n",
    "    \n",
    "    probas_1 = []\n",
    "    probas_2 = []\n",
    "    probas_3 = []\n",
    "    all_preds_1 = []\n",
    "    all_preds_2 = []\n",
    "    all_preds_3 = []\n",
    "    all_labels_1 = []\n",
    "    all_labels_2 = []\n",
    "    all_labels_3 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if mc_dropout:\n",
    "            print(\"use MC\")\n",
    "            for data_1, labels_1 in data_loader_1:\n",
    "                data_1 = data_1.to(device)\n",
    "                labels_1 = labels_1.to(device)\n",
    "\n",
    "                outputs_1 = torch.zeros_like(model_1(data_1))  # create a zero tensor of the same size as the model output\n",
    "                for _ in range(T):\n",
    "                    outputs_1 += model_1(data_1)\n",
    "                outputs_1 /= T  # take the average over T runs\n",
    "\n",
    "                probas_1.append(F.softmax(outputs_1, dim=1).cpu())\n",
    "                all_preds_1.append(outputs_1.argmax(dim=1).cpu())\n",
    "                all_labels_1.append(labels_1.cpu())\n",
    "\n",
    "            for data_2, labels_2 in data_loader_2:\n",
    "                data_2 = data_2.to(device)\n",
    "                labels_2 = labels_2.to(device)\n",
    "\n",
    "                outputs_2 = torch.zeros_like(model_2(data_2))  # create a zero tensor of the same size as the model output\n",
    "                for _ in range(T):\n",
    "                    outputs_2 += model_2(data_2)\n",
    "                outputs_2 /= T  # take the average over T runs\n",
    "\n",
    "                probas_2.append(F.softmax(outputs_2, dim=1).cpu())\n",
    "                all_preds_2.append(outputs_2.argmax(dim=1).cpu())\n",
    "                all_labels_2.append(labels_2.cpu())\n",
    "\n",
    "            for data_3, labels_3 in data_loader_3:\n",
    "                data_3 = data_3.to(device)\n",
    "                labels_3 = labels_3.to(device)\n",
    "\n",
    "                outputs_3 = torch.zeros_like(model_3(data_3))  # create a zero tensor of the same size as the model output\n",
    "                for _ in range(T):\n",
    "                    outputs_3 += model_3(data_3)\n",
    "                outputs_3 /= T  # take the average over T runs\n",
    "\n",
    "                probas_3.append(F.softmax(outputs_3, dim=1).cpu())\n",
    "                all_preds_3.append(outputs_3.argmax(dim=1).cpu())\n",
    "                all_labels_3.append(labels_3.cpu())\n",
    "        else:\n",
    "            print(\"use no MC\")\n",
    "            for data_1, labels_1,_ in data_loader_1:\n",
    "                data_1 = data_1.to(device)\n",
    "                labels_1 = labels_1.to(device)\n",
    "\n",
    "                outputs_1 = model_1(data_1)\n",
    "                probas_1.append(F.softmax(outputs_1, dim=1).cpu())\n",
    "                all_preds_1.append(outputs_1.argmax(dim=1).cpu())\n",
    "                all_labels_1.append(labels_1.cpu())\n",
    "\n",
    "            for data_2, labels_2,_ in data_loader_2:\n",
    "                data_2 = data_2.to(device)\n",
    "                labels_2 = labels_2.to(device)\n",
    "\n",
    "                outputs_2 = model_2(data_2)\n",
    "                probas_2.append(F.softmax(outputs_2, dim=1).cpu())\n",
    "                all_preds_2.append(outputs_2.argmax(dim=1).cpu())\n",
    "                all_labels_2.append(labels_2.cpu())\n",
    "\n",
    "            for data_3, labels_3,_ in data_loader_3:\n",
    "                data_3 = data_3.to(device)\n",
    "                labels_3 = labels_3.to(device)\n",
    "\n",
    "                outputs_3 = model_3(data_3)\n",
    "                probas_3.append(F.softmax(outputs_3, dim=1).cpu())\n",
    "                all_preds_3.append(outputs_3.argmax(dim=1).cpu())\n",
    "                all_labels_3.append(labels_3.cpu())\n",
    "\n",
    "    probas_1 = torch.cat(probas_1)\n",
    "    probas_2 = torch.cat(probas_2)\n",
    "    probas_3 = torch.cat(probas_3)\n",
    "\n",
    "    all_preds_1 = torch.cat(all_preds_1).numpy()\n",
    "    all_preds_2 = torch.cat(all_preds_2).numpy()\n",
    "    all_preds_3 = torch.cat(all_preds_3).numpy()\n",
    "\n",
    "    all_labels_1 = torch.cat(all_labels_1).numpy()\n",
    "    all_labels_2 = torch.cat(all_labels_2).numpy()\n",
    "    all_labels_3 = torch.cat(all_labels_3).numpy()\n",
    "\n",
    "    accuracy_1 = (all_labels_1 == all_preds_1).mean()\n",
    "    accuracy_2 = (all_labels_2 == all_preds_2).mean()\n",
    "    accuracy_3 = (all_labels_3 == all_preds_3).mean()\n",
    "\n",
    "    \n",
    "    print(phase+\"acc_1: \",accuracy_1,phase+\"acc_2: \",accuracy_2,phase+\"acc_3: \",accuracy_3)\n",
    "    \n",
    "    calibration_error = 0\n",
    "    \n",
    "\n",
    "    probs_1 = probas_1.cuda()\n",
    "    probs_2 = probas_2.cuda()\n",
    "    probs_3 = probas_3.cuda()\n",
    "    \n",
    "    all_labels_1 = torch.from_numpy(all_labels_1).cuda()\n",
    "    all_labels_2 = torch.from_numpy(all_labels_2).cuda()\n",
    "    all_labels_3 = torch.from_numpy(all_labels_3).cuda()\n",
    "    all_labels = all_labels_1\n",
    "    \n",
    "    all_preds_1 = torch.from_numpy(all_preds_1).cuda()\n",
    "    all_preds_2 = torch.from_numpy(all_preds_2).cuda()\n",
    "    all_preds_3 = torch.from_numpy(all_preds_3).cuda()\n",
    "    \n",
    "    if phase == \"val\" or 'train':\n",
    "        \n",
    "        uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_1,all_labels_1)\n",
    "        val_uce_list_ep1.append(uce_expert1)\n",
    "        val_uce_list_ep1.append(bin_uncertainties_expert1)\n",
    "        val_uce_list_ep1.append(bin_errors_expert1)\n",
    "        val_uce_list_ep1.append(prop_in_bin_values_expert1)\n",
    "        val_uce_list_ep1.append(bin_n_samples_ep1)\n",
    "        val_uce_list_ep1.append(bin_variances_ep1)\n",
    "        \n",
    "        uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_2, all_labels_2)\n",
    "        val_uce_list_ep2.append(uce_expert2)\n",
    "        val_uce_list_ep2.append(bin_uncertainties_expert2)\n",
    "        val_uce_list_ep2.append(bin_errors_expert2)\n",
    "        val_uce_list_ep2.append(prop_in_bin_values_expert2)\n",
    "        val_uce_list_ep2.append(bin_n_samples_ep2)\n",
    "        val_uce_list_ep2.append(bin_variances_ep2)\n",
    "        \n",
    "        uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_3, all_labels_3)\n",
    "        val_uce_list_ep3.append(uce_expert3)\n",
    "        val_uce_list_ep3.append(bin_uncertainties_expert3)\n",
    "        val_uce_list_ep3.append(bin_errors_expert3)\n",
    "        val_uce_list_ep3.append(prop_in_bin_values_expert3)\n",
    "        val_uce_list_ep3.append(bin_n_samples_ep3)\n",
    "        val_uce_list_ep3.append(bin_variances_ep3)\n",
    "\n",
    "    \n",
    "    if phase == \"test\": \n",
    "        \n",
    "        uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_1,all_labels_1)       \n",
    "        uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_2, all_labels_2)\n",
    "        uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_3, all_labels_3)\n",
    "        print(phase+\" uce_expert1: \",float(uce_expert1),phase+\" uce_expert2: \",float(uce_expert2),phase+\" uce_expert3: \",float(uce_expert3))\n",
    "        \n",
    "#         plot_and_save_confusion_matrix(probs_1,all_labels_1,'plt/confusion_matrix/'+save_name+'1.svg')\n",
    "#         plot_and_save_confusion_matrix(probs_2,all_labels_2,'plt/confusion_matrix/'+save_name+'2.svg')\n",
    "#         plot_and_save_confusion_matrix(probs_3,all_labels_3,'plt/confusion_matrix/'+save_name+'3.svg')\n",
    "        \n",
    "        plot_dot_UCE_diagram( uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1,1)\n",
    "        plot_dot_UCE_diagram( uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2,2)\n",
    "        plot_dot_UCE_diagram( uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3,3)\n",
    "        \n",
    "        \n",
    "        weight_ep1 = 1.0\n",
    "        weight_ep2 = 1.0\n",
    "        weight_ep3 = 1.0\n",
    "        \n",
    "#         print(probs_1.size())\n",
    "        table_pred_ep12 =   choose_best_expert_ex(probs_1, probs_2, all_labels,val_uce_list_ep1,val_uce_list_ep2,weight_ep1,weight_ep2)\n",
    "#         print(table_pred_ep12.size(),all_labels.size())\n",
    "        table_acc_ep12 = cal_accuracy(table_pred_ep12,all_labels)\n",
    "\n",
    "        table_expert_ep13 = choose_best_expert_ex(probs_1, probs_3, all_labels,val_uce_list_ep1,val_uce_list_ep3,weight_ep1,weight_ep3)\n",
    "        table_acc_ep13 = cal_accuracy(table_expert_ep13,all_labels)\n",
    "\n",
    "        table_pred_ep23 =   choose_best_expert_ex(probs_2, probs_3, all_labels,val_uce_list_ep2,val_uce_list_ep3,weight_ep2,weight_ep3)\n",
    "        table_acc_ep23 = cal_accuracy(table_pred_ep23,all_labels)\n",
    "\n",
    "        # 計算3位專家綜合準確度\n",
    "        tabel_pred_ep123 = choose_best_three_expert(probs_1,probs_2,probs_3,all_labels,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3)\n",
    "        tabel_acc_ep123 = cal_accuracy(tabel_pred_ep123,all_labels)\n",
    "        print(\"-----------------------------ensemble_learning-----------------------------------\")\n",
    "        print(\"12:\",table_acc_ep12,\"23\",table_acc_ep23,\"13\",table_acc_ep13,\"tabel_acc_ep123\",tabel_acc_ep123)\n",
    "        \n",
    "        \n",
    "        simple_voting_pred =voting(all_preds_1, all_preds_2, all_preds_3,3).cuda()\n",
    "        simple_voting_acc_123 =cal_accuracy(simple_voting_pred,all_labels)\n",
    "        \n",
    "        simple_voting_pred =voting2(all_preds_1, all_preds_2,2).cuda()\n",
    "        simple_voting_acc_12 =cal_accuracy(simple_voting_pred,all_labels)\n",
    "        \n",
    "        simple_voting_pred =voting2(all_preds_1, all_preds_3,1).cuda()\n",
    "        simple_voting_acc_13 =cal_accuracy(simple_voting_pred,all_labels)\n",
    "        \n",
    "        simple_voting_pred =voting2(all_preds_2, all_preds_3,2).cuda()\n",
    "        simple_voting_acc_23 =cal_accuracy(simple_voting_pred,all_labels)\n",
    "        \n",
    "        #加權投票，都不一樣選2\n",
    "        weighted_voting_pred =weighted_voting(all_preds_1, all_preds_2, all_preds_3,[0.6,0.3,0.1],2).cuda()\n",
    "        weighted_voting_acc_123 =cal_accuracy(weighted_voting_pred,all_labels)\n",
    "    \n",
    "        weighted_voting_pred =weighted_voting2(all_preds_1, all_preds_2, [0.8,0.2],2).cuda()\n",
    "        weighted_voting_acc_12 =cal_accuracy(weighted_voting_pred,all_labels)\n",
    "        \n",
    "        weighted_voting_pred =weighted_voting2(all_preds_1, all_preds_3, [0.7,0.3],1).cuda()\n",
    "        weighted_voting_acc_13 =cal_accuracy(weighted_voting_pred,all_labels)\n",
    "        \n",
    "        weighted_voting_pred =weighted_voting2(all_preds_2, all_preds_3, [0.8,0.2],1).cuda()\n",
    "        weighted_voting_acc_23 =cal_accuracy(weighted_voting_pred,all_labels)\n",
    "        \n",
    "        #Product of Experts 綜合ep13\n",
    "        def POE_acc(probs_1,probs_2,all_labels):\n",
    "            POE_probs_ = torch.stack([probs_1, probs_2])\n",
    "            POE_probs = product_of_experts(POE_probs_)\n",
    "            POE_pred = torch.argmax(POE_probs, axis=1)\n",
    "            POE_acc =cal_accuracy(POE_pred,all_labels)\n",
    "            return POE_acc\n",
    "        def SOE_acc(probs_1,probs_2,all_labels):\n",
    "            SOE_probs = (probs_1+probs_2)/2\n",
    "            SOE_pred = torch.argmax(SOE_probs, axis=1)\n",
    "            SOE_acc =cal_accuracy(SOE_pred,all_labels)\n",
    "            return SOE_acc\n",
    "        POE_12=POE_acc(probs_1,probs_2,all_labels)\n",
    "        POE_13=POE_acc(probs_1,probs_3,all_labels)\n",
    "        POE_23=POE_acc(probs_2,probs_3,all_labels)\n",
    "        \n",
    "        SOE_12=SOE_acc(probs_1,probs_2,all_labels)\n",
    "        SOE_13=SOE_acc(probs_1,probs_3,all_labels)\n",
    "        SOE_23=SOE_acc(probs_2,probs_3,all_labels)\n",
    "        \n",
    "        POE_probs_ = torch.stack([probs_1, probs_2,probs_3])\n",
    "        POE_probs = product_of_experts(POE_probs_)\n",
    "        POE_pred = torch.argmax(POE_probs, axis=1)\n",
    "        POE_123 =cal_accuracy(POE_pred,all_labels)\n",
    "        \n",
    "        SOE_probs = (probs_1+probs_2+probs_3)/3\n",
    "        SOE_pred = torch.argmax(SOE_probs, axis=1)\n",
    "        SOE_123 =cal_accuracy(SOE_pred,all_labels)\n",
    "        \n",
    "        \n",
    "        print(\"simple_voting_acc: \")\n",
    "        print(\"12\",simple_voting_acc_12,\"23\",simple_voting_acc_23,\"13\",simple_voting_acc_13,\"123\",simple_voting_acc_123)\n",
    "        print(\"weighted_voting_pred: \")\n",
    "        print(\"12\",weighted_voting_acc_12,\"23\",weighted_voting_acc_23,\"13\",weighted_voting_acc_13,\"123\",weighted_voting_acc_123)\n",
    "        print(\"POE_12: \",POE_12,\"POE_23: \",POE_23,\"POE_13: \",POE_13,\"POE_123: \",POE_123,)\n",
    "        print(\"SOE_12: \",SOE_12,\"SOE_23: \",SOE_23,\"SOE_13: \",SOE_13,\"SOE_123: \",SOE_123,)\n",
    "\n",
    "        \n",
    "        with open(save_name+'output_data.csv', 'a', newline='') as csvfile:  # 使用'a'模式以追加數據到文件\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "\n",
    "            # 寫入標題\n",
    "            csv_writer.writerow(['Type', '12', '13', '23', '123'])\n",
    "\n",
    "            csv_writer.writerow(['table_acc', table_acc_ep12, table_acc_ep13, table_acc_ep23,tabel_acc_ep123])\n",
    "            # 寫入simple_voting_acc資料\n",
    "\n",
    "            # 寫入SOE資料\n",
    "            csv_writer.writerow(['SOE', SOE_12, SOE_13, SOE_23, SOE_123]) \n",
    "\n",
    "            # 寫入POE資料\n",
    "            csv_writer.writerow(['POE', POE_12, POE_13, POE_23, POE_123])\n",
    "\n",
    "            csv_writer.writerow(['simple_voting_acc', simple_voting_acc_12, simple_voting_acc_13, simple_voting_acc_23, simple_voting_acc_123])\n",
    "\n",
    "            # 寫入weighted_voting_pred資料\n",
    "            csv_writer.writerow(['weighted_voting_pred', weighted_voting_acc_12, weighted_voting_acc_13, weighted_voting_acc_23, weighted_voting_acc_123])\n",
    "\n",
    "\n",
    "            # 寫入準確度數據\n",
    "            csv_writer.writerow(['accuracy', accuracy_1, accuracy_2, accuracy_3])\n",
    "\n",
    "            # 寫入UCE數據\n",
    "            csv_writer.writerow(['uce_expert', float(uce_expert1), float(uce_expert2), float(uce_expert3)])\n",
    "\n",
    "        print(\"資料已存入output_data.csv\")        \n",
    "        \n",
    "    accuracy = 0\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    return calibration_error, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503de11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def choose_best_three_expert(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "#     uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1, bin_variances_ep1 = compute_uce(probs_expert1, targets, n_bins)\n",
    "#     uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2, bin_variances_ep2 = compute_uce(probs_expert2, targets_pairs, n_bins)\n",
    "#     uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3, bin_variances_ep3 = compute_uce(probs_expert3, targets, n_bins)\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3]).to(device)\n",
    "\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                    torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "    \n",
    "    compute_mae_error_and_uncertainty(probs_expert1, probs_expert2, probs_expert3, targets,\n",
    "    uncertainties_expert1, uncertainties_expert2, uncertainties_expert3, error_rates_expert1, error_rates_expert2, error_rates_expert3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    global save_name\n",
    "    df = analyze_errors(error_rates, final_predictions, targets)\n",
    "    \n",
    "    # Check if the directory 'df' exists, if not, create it\n",
    "    if not os.path.exists('df'):\n",
    "        os.makedirs('df')\n",
    "    \n",
    "    # Save the dataframe to a CSV file in the 'df' directory\n",
    "    df.to_csv('df/'+save_name+'_error_analysis.csv', index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "std_deviation_per_position = None\n",
    "error_rates = None\n",
    "POE_pred = None\n",
    "final_predictions = None\n",
    "\n",
    "def choose_best_three_expert_new(probs_expert1,probs_expert2,probs_expert3 ,targets,val_uce_list_ep1,val_uce_list_ep2,val_uce_list_ep3, n_bins=10):\n",
    "    global std_deviation_per_position\n",
    "    global error_rates\n",
    "    global threshold_\n",
    "    global POE_pred\n",
    "    global final_predictions\n",
    "    uce_expert1, bin_uncertainties_expert1, bin_errors_expert1, prop_in_bin_values_expert1,bin_n_samples_ep1,bin_variances_ep1 = val_uce_list_ep1[0],val_uce_list_ep1[1],val_uce_list_ep1[2],val_uce_list_ep1[3],val_uce_list_ep1[4],val_uce_list_ep1[5]\n",
    "    uce_expert2, bin_uncertainties_expert2, bin_errors_expert2, prop_in_bin_values_expert2,bin_n_samples_ep2,bin_variances_ep2 = val_uce_list_ep2[0],val_uce_list_ep2[1],val_uce_list_ep2[2],val_uce_list_ep2[3],val_uce_list_ep2[4],val_uce_list_ep2[5]\n",
    "    uce_expert3, bin_uncertainties_expert3, bin_errors_expert3, prop_in_bin_values_expert3,bin_n_samples_ep3,bin_variances_ep3 = val_uce_list_ep3[0],val_uce_list_ep3[1],val_uce_list_ep3[2],val_uce_list_ep3[3],val_uce_list_ep3[4],val_uce_list_ep3[5]\n",
    "\n",
    "\n",
    "\n",
    "    # Compute uncertainties for both experts\n",
    "    _, nattrs = probs_expert1.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    uncertainties_expert1 = (1/torch.log(nattrs))*(-torch.sum(probs_expert1 * torch.log(probs_expert1 + 1e-12), dim=1))\n",
    "    uncertainties_expert2 = (1/torch.log(nattrs))*(-torch.sum(probs_expert2 * torch.log(probs_expert2 + 1e-12), dim=1))\n",
    "    uncertainties_expert3 = (1/torch.log(nattrs))*(-torch.sum(probs_expert3 * torch.log(probs_expert3 + 1e-12), dim=1))\n",
    "\n",
    "    # Find error rates for both experts\n",
    "    error_rates_expert1 = find_error_rates(uncertainties_expert1, bin_uncertainties_expert1, bin_errors_expert1)\n",
    "    error_rates_expert2 = find_error_rates(uncertainties_expert2, bin_uncertainties_expert2, bin_errors_expert2)\n",
    "    error_rates_expert3 = find_error_rates(uncertainties_expert3, bin_uncertainties_expert3, bin_errors_expert3)\n",
    "    # Choose the expert with lower error rate for each sample\n",
    "\n",
    "    # Get the predictions from both experts\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # 將三個錯誤率堆疊成一個張量\n",
    "    error_rates = torch.stack([error_rates_expert1, error_rates_expert2, error_rates_expert3])\n",
    "    \n",
    "    std_deviation_per_position = torch.std(error_rates, dim=0)\n",
    "    mean_value = torch.mean(std_deviation_per_position)\n",
    "    print(\"mean: \",mean_value)\n",
    "#     print(std_deviation_per_position)\n",
    "    # 找出最小錯誤率的索引\n",
    "    _, min_error_rate_indices = torch.min(error_rates, dim=0)\n",
    "    \n",
    "    POE_probs_ = torch.stack([probs_expert1, probs_expert2,probs_expert3])\n",
    "    POE_probs = product_of_experts(POE_probs_)\n",
    "    POE_pred = np.argmax(POE_probs, axis=1)\n",
    "    \n",
    "    POE_pred = torch.tensor(POE_pred)  # Convert numpy array to torch tensor\n",
    "\n",
    "    SOE_probs_ = (probs_expert1+probs_expert2+probs_expert3)/3\n",
    "    SOE_pred = np.argmax(SOE_probs_, axis=1)\n",
    "\n",
    "    # 根據最小錯誤率的索引選擇最終的預測\n",
    "    final_predictions = torch.where(min_error_rate_indices == 0, preds_expert1,\n",
    "                                      torch.where(min_error_rate_indices == 1, preds_expert2, preds_expert3))\n",
    "\n",
    "    initial_predictions_probs = torch.where(min_error_rate_indices.unsqueeze(-1) == 0, probs_expert1,\n",
    "                                           torch.where(min_error_rate_indices.unsqueeze(-1) == 1, probs_expert2, probs_expert3))\n",
    "    \n",
    "    POE_probs_ = torch.stack([POE_probs,SOE_probs_,initial_predictions_probs])\n",
    "    POE_initial_predictions_probs = product_of_experts(POE_probs_)\n",
    "    SOE_initial_predictions_probs = (SOE_probs_+POE_probs+initial_predictions_probs)/2\n",
    "    \n",
    "    POE_final_predictions = np.argmax(POE_initial_predictions_probs, axis=1)\n",
    "    \n",
    "    SOE_final_predictions = np.argmax(SOE_initial_predictions_probs, axis=1)\n",
    "    \n",
    "    POE_acc =accuracy(POE_final_predictions,targets)\n",
    "    SOE_acc =accuracy(SOE_final_predictions,targets)\n",
    "    print(\"POE_SPE_acc: \",POE_acc,\"SOE_SPE_acc: \",SOE_acc)\n",
    "#     threshold = torch.quantile(std_deviation_per_position, threshold_)\n",
    "\n",
    "#     threshold = torch.quantile(uncertainties_, threshold_)\n",
    "#     print(\"threshold: \",threshold)\n",
    "    # 根據 std_deviation_per_position 更新預測\n",
    "#     final_predictions = torch.where(std_deviation_per_position < threshold, POE_pred, initial_predictions)\n",
    "#     final_predictions = torch.where(std_deviation_per_position < threshold, initial_predictions , POE_pred)\n",
    "\n",
    "    return SOE_final_predictions\n",
    "\n",
    "def compute_uce(probs, targets, n_bins=10):\n",
    "    _, nattrs =probs.size()\n",
    "    nattrs = torch.tensor(nattrs)\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    uce = 0\n",
    "    bin_uncertainties = []\n",
    "    bin_errors = []\n",
    "    prop_in_bin_values = []\n",
    "    bin_n_samples = []\n",
    "    bin_variances = []\n",
    "    # Compute the uncertainty values (entropy)\n",
    "    uncertainties = (1/torch.log(nattrs))*(-torch.sum(probs * torch.log(probs + 1e-12), dim=1))\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (uncertainties >= bin_lower) * (uncertainties < bin_upper)\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        prop_in_bin_values.append(prop_in_bin.item() if prop_in_bin.item() > 0 else None)\n",
    "        if prop_in_bin.item() > 0:\n",
    "            sample_indices = torch.where(in_bin)[0]\n",
    "            bin_targets = targets[sample_indices]\n",
    "            bin_probs = probs[sample_indices]\n",
    "            error_in_bin = (bin_targets != torch.argmax(bin_probs, dim=1)).float().mean()\n",
    "            avg_uncertainty_in_bin = uncertainties[in_bin].mean()\n",
    "            uce += torch.abs(avg_uncertainty_in_bin - error_in_bin) * prop_in_bin\n",
    "            bin_uncertainties.append(avg_uncertainty_in_bin.item())\n",
    "            bin_errors.append(error_in_bin.item())\n",
    "            n_samples_in_bin = sample_indices.size(0)\n",
    "            bin_n_samples.append(n_samples_in_bin)\n",
    "            bin_variances.append(torch.var((bin_targets != torch.argmax(bin_probs, dim=1)).float()).item())\n",
    "        else:\n",
    "            bin_uncertainties.append(None)\n",
    "            bin_errors.append(None)\n",
    "            bin_n_samples.append(None)\n",
    "            bin_variances.append(None)\n",
    "\n",
    "    return uce, bin_uncertainties, bin_errors, prop_in_bin_values, bin_n_samples, bin_variances\n",
    "\n",
    "\n",
    "def compute_mae_error_and_uncertainty(probs_expert1, probs_expert2, probs_expert3, targets, uncertainties_expert1, uncertainties_expert2, uncertainties_expert3, error_rates_expert1, error_rates_expert2, error_rates_expert3):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    avg_uncertainty = (uncertainties_expert1 + uncertainties_expert2 + uncertainties_expert3) / 3\n",
    "    error_rates_expert1 = error_rates_expert1.to(device)\n",
    "    error_rates_expert2 = error_rates_expert2.to(device)\n",
    "    error_rates_expert3 = error_rates_expert3.to(device)\n",
    "    \n",
    "    # Get the predictions from each expert\n",
    "    preds_expert1 = torch.argmax(probs_expert1, dim=1)\n",
    "    preds_expert2 = torch.argmax(probs_expert2, dim=1)\n",
    "    preds_expert3 = torch.argmax(probs_expert3, dim=1)\n",
    "\n",
    "    # Calculate the real error rates\n",
    "    real_error_expert1 = (preds_expert1 != targets).float().mean()\n",
    "    real_error_expert2 = (preds_expert2 != targets).float().mean()\n",
    "    real_error_expert3 = (preds_expert3 != targets).float().mean()\n",
    "    \n",
    "    \n",
    "    # Calculate MAE for error rates\n",
    "    mae_error_expert1 = torch.abs(error_rates_expert1 - real_error_expert1).mean()\n",
    "    mae_error_expert2 = torch.abs(error_rates_expert2 - real_error_expert2).mean()\n",
    "    mae_error_expert3 = torch.abs(error_rates_expert3 - real_error_expert3).mean()\n",
    "    \n",
    "\n",
    "#     # Calculate MAE for uncertainties using average uncertainty as the reference\n",
    "#     mae_uncertainty_expert1 = torch.abs(uncertainties_expert1 - avg_uncertainty).mean()\n",
    "#     mae_uncertainty_expert2 = torch.abs(uncertainties_expert2 - avg_uncertainty).mean()\n",
    "#     mae_uncertainty_expert3 = torch.abs(uncertainties_expert3 - avg_uncertainty).mean()\n",
    "\n",
    "    # Print results\n",
    "    print(\"MAE Error Expert 1:\", mae_error_expert1.item())\n",
    "    print(\"MAE Error Expert 2:\", mae_error_expert2.item())\n",
    "    print(\"MAE Error Expert 3:\", mae_error_expert3.item())\n",
    "#     print(\"MAE Uncertainty Expert 1:\", mae_uncertainty_expert1.item())\n",
    "#     print(\"MAE Uncertainty Expert 2:\", mae_uncertainty_expert2.item())\n",
    "#     print(\"MAE Uncertainty Expert 3:\", mae_uncertainty_expert3.item())\n",
    "    \n",
    "    \n",
    "def analyze_errors(error_rates, final_predictions, targets, n_samples=500):\n",
    "    samples_idx = torch.randint(0, len(targets), (n_samples,))\n",
    "    \n",
    "    expert1_error_rates = error_rates[0][samples_idx].tolist()\n",
    "    expert2_error_rates = error_rates[1][samples_idx].tolist()\n",
    "    expert3_error_rates = error_rates[2][samples_idx].tolist()\n",
    "    \n",
    "    spe_results = final_predictions[samples_idx].tolist()\n",
    "    real_results = targets[samples_idx].tolist()\n",
    "    \n",
    "    # Checking if SPE results are correct\n",
    "    spe_is_correct = [1 if spe_results[i] == real_results[i] else 0 for i in range(n_samples)]\n",
    "    \n",
    "    data = {\n",
    "        \"專家1錯誤率\": expert1_error_rates,\n",
    "        \"專家2錯誤率\": expert2_error_rates,\n",
    "        \"專家3錯誤率\": expert3_error_rates,\n",
    "        \"SPE選擇結果\": spe_results,\n",
    "        \"真實結果\": real_results,\n",
    "        \"SPE結果是否正確\": spe_is_correct\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data, index=[f\"樣本{i+1}\" for i in range(n_samples)])\n",
    "    \n",
    "    # Analyze the variance\n",
    "    correct_predictions = df[df[\"SPE結果是否正確\"] == 1]\n",
    "    incorrect_predictions = df[df[\"SPE結果是否正確\"] == 0]\n",
    "    \n",
    "    variance_correct = (correct_predictions[[\"專家1錯誤率\", \"專家2錯誤率\", \"專家3錯誤率\"]].var(axis=1).mean())\n",
    "    variance_incorrect = (incorrect_predictions[[\"專家1錯誤率\", \"專家2錯誤率\", \"專家3錯誤率\"]].var(axis=1).mean())\n",
    "    \n",
    "    print(\"Average variance for correctly predicted samples:\", variance_correct)\n",
    "    print(\"Average variance for incorrectly predicted samples:\", variance_incorrect)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18afad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f30a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with different split = 3\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Training model with different split = 4\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Training model with different split = 5\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "\n",
      "Loading and testing model with seed = 3 and dropout_rate = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and testing model with seed = 4 and dropout_rate = 0.5\n",
      "\n",
      "Loading and testing model with seed = 5 and dropout_rate = 0.5\n",
      "\n",
      "Testing on validation set:\n",
      "use no MC\n",
      "trainacc_1:  0.7344241211774792 trainacc_2:  0.7229208345241498 trainacc_3:  0.7219205487282081\n",
      "Validation Calibration Error: 0, Validation Accuracy: 0\n",
      "\n",
      "\n",
      "Testing on test set:\n",
      "------------------------epochs 20 ------------------------------------------\n",
      "dropout_rate:  0.5\n",
      "use no MC\n",
      "testacc_1:  0.6207 testacc_2:  0.6195 testacc_3:  0.6474\n",
      "test uce_expert1:  0.11675038933753967 test uce_expert2:  0.05922088027000427 test uce_expert3:  0.23270516097545624\n",
      "MAE Error Expert 1: 0.22738304734230042\n",
      "MAE Error Expert 2: 0.2504487633705139\n",
      "MAE Error Expert 3: 0.19599711894989014\n",
      "Average variance for correctly predicted samples: 0.011073343945574503\n",
      "Average variance for incorrectly predicted samples: 0.01119238963279057\n",
      "-----------------------------ensemble_learning-----------------------------------\n",
      "12: 0.6369 23 0.6536 13 0.6521 tabel_acc_ep123 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_voting_acc: \n",
      "12 0.6195 23 0.6474 13 0.6207 123 0.6474\n",
      "weighted_voting_pred: \n",
      "12 0.6207 23 0.6195 13 0.6207 123 0.6207\n",
      "POE_12:  0.6277 POE_23:  0.6484 POE_13:  0.632 POE_123:  0.6357\n",
      "SOE_12:  0.6301 SOE_23:  0.6476 SOE_13:  0.6331 SOE_123:  0.6379\n",
      "資料已存入output_data.csv\n",
      "Test Calibration Error: 0, Test Accuracy: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_fold = \"1_\"\n",
    "save_name = '1_focal_best'\n",
    "batch_size = 512\n",
    "num_workers = 4\n",
    "imb_ratio = 50\n",
    "\n",
    "# 建立一個字典來存儲每個數據加載器\n",
    "data_loaders = {}\n",
    "\n",
    "val_uce_list_ep1 = []\n",
    "val_uce_list_ep2 = []\n",
    "val_uce_list_ep3 = []\n",
    "\n",
    "\n",
    "for seed in [3,4,5]:\n",
    "    print(f\"Training model with different split = {seed}\")\n",
    "\n",
    "    trainloader, valloader, testloader = create_dataloaders(seed, batch_size,imb_ratio)        \n",
    "    \n",
    "    # 存儲進字典，作為該模型的數據加載器\n",
    "    data_loaders[f'data_loader_{seed}'] = {\n",
    "        'train': trainloader, \n",
    "        'val': valloader, \n",
    "        'test': testloader\n",
    "    }\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# seeds = [3, 4]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models = {}  # Store models in a dictionary\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = 1\n",
    "\n",
    "seeds = [3,4,5]\n",
    "for seed in seeds:\n",
    "    print(f\"\\nLoading and testing model with seed = {seed} and dropout_rate = {dropout_rate}\")\n",
    "    model = create_model(mc_dropout=False, dropout_rate=dropout_rate)  # Assuming same model structure\n",
    "    model = model.to(device)\n",
    "    model_path = f\"./model/\"+save_model +\"_best_model_seed_{seed}.pt\"\n",
    "    model = load_model(model, model_path)  # Load from saved model\n",
    "    models[f\"model_{seed}\"] = model  # Store the model in the dictionary with a unique key\n",
    "\n",
    "    \n",
    "\n",
    "print(\"\\nTesting on validation set:\")\n",
    "val_calibration_error, val_accuracy = ensemble_learning(models, data_loaders, criterion, device,\"train\",mc_dropout=False)\n",
    "print(f\"Validation Calibration Error: {val_calibration_error}, Validation Accuracy: {val_accuracy}\\n\")\n",
    "\n",
    "print(\"\\nTesting on test set:\")\n",
    "print(\"------------------------epochs\",num_epochs ,\"------------------------------------------\")\n",
    "print(\"dropout_rate: \",dropout_rate)\n",
    "test_calibration_error, test_accuracy = ensemble_learning(models, data_loaders, criterion, device,\"test\",mc_dropout=False)\n",
    "print(f\"Test Calibration Error: {test_calibration_error}, Test Accuracy: {test_accuracy}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ba258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e9c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with different split = 3\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Training model with different split = 4\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Training model with different split = 5\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "\n",
      "Loading and testing model with seed = 3 and dropout_rate = 0.5\n",
      "\n",
      "Loading and testing model with seed = 4 and dropout_rate = 0.5\n",
      "\n",
      "Loading and testing model with seed = 5 and dropout_rate = 0.5\n",
      "\n",
      "Testing on validation set:\n",
      "use no MC\n",
      "trainacc_1:  0.7362817947985139 trainacc_2:  0.7635753072306374 trainacc_3:  0.710488711060303\n",
      "Validation Calibration Error: 0, Validation Accuracy: 0\n",
      "\n",
      "\n",
      "Testing on test set:\n",
      "------------------------epochs 20 ------------------------------------------\n",
      "dropout_rate:  0.5\n",
      "use no MC\n",
      "testacc_1:  0.6297 testacc_2:  0.7276 testacc_3:  0.6149\n",
      "test uce_expert1:  0.10861764848232269 test uce_expert2:  0.07762288302183151 test uce_expert3:  0.18729981780052185\n",
      "MAE Error Expert 1: 0.22119519114494324\n",
      "MAE Error Expert 2: 0.188756063580513\n",
      "MAE Error Expert 3: 0.2390875667333603\n",
      "Average variance for correctly predicted samples: 0.010619653427959773\n",
      "Average variance for incorrectly predicted samples: 0.012692997171086629\n",
      "-----------------------------ensemble_learning-----------------------------------\n",
      "12: 0.719 23 0.7187 13 0.6382 tabel_acc_ep123 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_voting_acc: \n",
      "12 0.7276 23 0.6149 13 0.6297 123 0.6149\n",
      "weighted_voting_pred: \n",
      "12 0.6297 23 0.7276 13 0.6297 123 0.6297\n",
      "POE_12:  0.6813 POE_23:  0.7101 POE_13:  0.6433 POE_123:  0.6809\n",
      "SOE_12:  0.683 SOE_23:  0.7162 SOE_13:  0.6431 SOE_123:  0.6906\n",
      "資料已存入output_data.csv\n",
      "Test Calibration Error: 0, Test Accuracy: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_fold = \"2_\"\n",
    "save_name = '2_focal_best'\n",
    "batch_size = 512\n",
    "num_workers = 4\n",
    "imb_ratio = 50\n",
    "\n",
    "# 建立一個字典來存儲每個數據加載器\n",
    "data_loaders = {}\n",
    "\n",
    "val_uce_list_ep1 = []\n",
    "val_uce_list_ep2 = []\n",
    "val_uce_list_ep3 = []\n",
    "\n",
    "\n",
    "for seed in [3,4,5]:\n",
    "    print(f\"Training model with different split = {seed}\")\n",
    "\n",
    "    trainloader, valloader, testloader = create_dataloaders(seed, batch_size,imb_ratio)        \n",
    "    \n",
    "    # 存儲進字典，作為該模型的數據加載器\n",
    "    data_loaders[f'data_loader_{seed}'] = {\n",
    "        'train': trainloader, \n",
    "        'val': valloader, \n",
    "        'test': testloader\n",
    "    }\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# seeds = [3, 4]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models = {}  # Store models in a dictionary\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = 1\n",
    "\n",
    "seeds = [3,4,5]\n",
    "for seed in seeds:\n",
    "    print(f\"\\nLoading and testing model with seed = {seed} and dropout_rate = {dropout_rate}\")\n",
    "    model = create_model(mc_dropout=False, dropout_rate=dropout_rate)  # Assuming same model structure\n",
    "    model = model.to(device)\n",
    "    model_path = f\"./model/\"+save_model +\"_best_model_seed_{seed}.pt\"\n",
    "    model = load_model(model, model_path)  # Load from saved model\n",
    "    models[f\"model_{seed}\"] = model  # Store the model in the dictionary with a unique key\n",
    "\n",
    "    \n",
    "\n",
    "print(\"\\nTesting on validation set:\")\n",
    "val_calibration_error, val_accuracy = ensemble_learning(models, data_loaders, criterion, device,\"train\",mc_dropout=False)\n",
    "print(f\"Validation Calibration Error: {val_calibration_error}, Validation Accuracy: {val_accuracy}\\n\")\n",
    "\n",
    "print(\"\\nTesting on test set:\")\n",
    "print(\"------------------------epochs\",num_epochs ,\"------------------------------------------\")\n",
    "print(\"dropout_rate: \",dropout_rate)\n",
    "test_calibration_error, test_accuracy = ensemble_learning(models, data_loaders, criterion, device,\"test\",mc_dropout=False)\n",
    "print(f\"Test Calibration Error: {test_calibration_error}, Test Accuracy: {test_accuracy}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "366c093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with different split = 3\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Training model with different split = 4\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Training model with different split = 5\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_train.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "train Mode: Contain 13996 images\n",
      "13996\n",
      "No sampler.\n",
      "Shuffle is True.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_val.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "val Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "Loading data from ./data/CIFAR10_LT/CIFAR10_LT_test.txt\n",
      "====> CIFAR10 Imbalance Ratio:  50\n",
      "Files already downloaded and verified\n",
      "test Mode: Contain 10000 images\n",
      "10000\n",
      "No sampler.\n",
      "Shuffle is False.\n",
      "\n",
      "Loading and testing model with seed = 3 and dropout_rate = 0.5\n",
      "\n",
      "Loading and testing model with seed = 4 and dropout_rate = 0.5\n",
      "\n",
      "Loading and testing model with seed = 5 and dropout_rate = 0.5\n",
      "\n",
      "Testing on validation set:\n",
      "use no MC\n",
      "trainacc_1:  0.7360674478422407 trainacc_2:  0.7612889396970564 trainacc_3:  0.70120034295513\n",
      "Validation Calibration Error: 0, Validation Accuracy: 0\n",
      "\n",
      "\n",
      "Testing on test set:\n",
      "------------------------epochs 20 ------------------------------------------\n",
      "dropout_rate:  0.5\n",
      "use no MC\n",
      "testacc_1:  0.6233 testacc_2:  0.7361 testacc_3:  0.6522\n",
      "test uce_expert1:  0.10695912688970566 test uce_expert2:  0.10965465754270554 test uce_expert3:  0.27865922451019287\n",
      "MAE Error Expert 1: 0.23934811353683472\n",
      "MAE Error Expert 2: 0.18149416148662567\n",
      "MAE Error Expert 3: 0.1826634556055069\n",
      "Average variance for correctly predicted samples: 0.01174300742104547\n",
      "Average variance for incorrectly predicted samples: 0.017023276039319617\n",
      "-----------------------------ensemble_learning-----------------------------------\n",
      "12: 0.732 23 0.7311 13 0.6699 tabel_acc_ep123 0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebooks/anaconda3/envs/clip/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_voting_acc: \n",
      "12 0.7361 23 0.6522 13 0.6233 123 0.6522\n",
      "weighted_voting_pred: \n",
      "12 0.6233 23 0.7361 13 0.6233 123 0.6233\n",
      "POE_12:  0.6924 POE_23:  0.7314 POE_13:  0.6427 POE_123:  0.6951\n",
      "SOE_12:  0.6973 SOE_23:  0.738 SOE_13:  0.6433 SOE_123:  0.7027\n",
      "資料已存入output_data.csv\n",
      "Test Calibration Error: 0, Test Accuracy: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_fold = \"3_\"\n",
    "save_name = '3_focal_best'\n",
    "batch_size = 512\n",
    "num_workers = 4\n",
    "imb_ratio = 50\n",
    "\n",
    "# 建立一個字典來存儲每個數據加載器\n",
    "data_loaders = {}\n",
    "\n",
    "val_uce_list_ep1 = []\n",
    "val_uce_list_ep2 = []\n",
    "val_uce_list_ep3 = []\n",
    "\n",
    "\n",
    "for seed in [3,4,5]:\n",
    "    print(f\"Training model with different split = {seed}\")\n",
    "\n",
    "    trainloader, valloader, testloader = create_dataloaders(seed, batch_size,imb_ratio)        \n",
    "    \n",
    "    # 存儲進字典，作為該模型的數據加載器\n",
    "    data_loaders[f'data_loader_{seed}'] = {\n",
    "        'train': trainloader, \n",
    "        'val': valloader, \n",
    "        'test': testloader\n",
    "    }\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# seeds = [3, 4]\n",
    "dropout_rate = 0.5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models = {}  # Store models in a dictionary\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = 1\n",
    "\n",
    "seeds = [3,4,5]\n",
    "for seed in seeds:\n",
    "    print(f\"\\nLoading and testing model with seed = {seed} and dropout_rate = {dropout_rate}\")\n",
    "    model = create_model(mc_dropout=False, dropout_rate=dropout_rate)  # Assuming same model structure\n",
    "    model = model.to(device)\n",
    "    model_path = f\"./model/\"+save_model +\"_best_model_seed_{seed}.pt\"\n",
    "    model = load_model(model, model_path)  # Load from saved model\n",
    "    models[f\"model_{seed}\"] = model  # Store the model in the dictionary with a unique key\n",
    "\n",
    "    \n",
    "\n",
    "print(\"\\nTesting on validation set:\")\n",
    "val_calibration_error, val_accuracy = ensemble_learning(models, data_loaders, criterion, device,\"train\",mc_dropout=False)\n",
    "print(f\"Validation Calibration Error: {val_calibration_error}, Validation Accuracy: {val_accuracy}\\n\")\n",
    "\n",
    "print(\"\\nTesting on test set:\")\n",
    "print(\"------------------------epochs\",num_epochs ,\"------------------------------------------\")\n",
    "print(\"dropout_rate: \",dropout_rate)\n",
    "test_calibration_error, test_accuracy = ensemble_learning(models, data_loaders, criterion, device,\"test\",mc_dropout=False)\n",
    "print(f\"Test Calibration Error: {test_calibration_error}, Test Accuracy: {test_accuracy}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baecead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
